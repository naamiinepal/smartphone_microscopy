{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.ops import box_iou\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/mnt/Enterprise/safal/AI_assisted_microscopy_system/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_annotation_file = os.path.join(\n",
    "    BASE_DIR,\n",
    "    \"cysts_dataset_all/smartphone_sample/fold_5/smartphone_sample_coco_annos_val.json\",\n",
    ")\n",
    "\n",
    "pred_annotation_file = os.path.join(\n",
    "    BASE_DIR,\n",
    "    \"outputs/smartphone_sample/faster_rcnn_x101_32x8d_fpn_mstrain_3x_coco/fold_5/results.bbox.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_annotations = json.load(open(gt_annotation_file))\n",
    "pred_annotations = json.load(open(pred_annotation_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_annotations_df = pd.DataFrame(gt_annotations[\"annotations\"])\n",
    "pred_annotations_df = pd.DataFrame(pred_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change bbox width and height to x2, y2\n",
    "pred_annotations_df[\"bbox\"] = pred_annotations_df[\"bbox\"].apply(\n",
    "    lambda x: [x[0], x[1], x[0] + x[2], x[1] + x[3]]\n",
    ")\n",
    "gt_annotations_df[\"bbox\"] = gt_annotations_df[\"bbox\"].apply(\n",
    "    lambda x: [x[0], x[1], x[0] + x[2], x[1] + x[3]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[240, 259, 405, 505, 744]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the image ids which have both category ids 0 and 1\n",
    "image_ids = gt_annotations_df[\"image_id\"].unique()\n",
    "image_ids = [\n",
    "    image_id\n",
    "    for image_id in image_ids\n",
    "    if 0 in gt_annotations_df[gt_annotations_df[\"image_id\"] == image_id][\"category_id\"].values\n",
    "    and 1 in gt_annotations_df[gt_annotations_df[\"image_id\"] == image_id][\"category_id\"].values\n",
    "]\n",
    "\n",
    "image_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    6,   24,   26,   36,   37,   48,   53,   56,   57,   81,\n",
       "         94,   99,  107,  123,  136,  141,  146,  151,  154,  158,  159,\n",
       "        181,  198,  203,  208,  240,  243,  244,  245,  255,  259,  282,\n",
       "        284,  287,  305,  309,  310,  320,  325,  326,  358,  359,  360,\n",
       "        362,  372,  373,  397,  398,  402,  405,  422,  432,  448,  456,\n",
       "        459,  486,  496,  498,  503,  505,  530,  539,  547,  550,  557,\n",
       "        560,  564,  566,  568,  574,  579,  588,  600,  608,  654,  655,\n",
       "        660,  661,  663,  669,  681,  682,  683,  693,  702,  704,  705,\n",
       "        713,  718,  725,  727,  744,  749,  772,  779,  792,  794,  795,\n",
       "        799,  803,  804,  805,  807,  816,  817,  825,  845,  855,  869,\n",
       "        876,  895,  896,  897,  905,  920,  931,  934,  946,  948,  954,\n",
       "        976,  987,  993, 1028, 1032, 1044, 1048])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_annotations_df.image_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>score</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37</td>\n",
       "      <td>[1719.8165283203125, 1541.7166748046875, 1764....</td>\n",
       "      <td>0.526125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>37</td>\n",
       "      <td>[1716.9451904296875, 1537.9757080078125, 1770....</td>\n",
       "      <td>0.065791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id                                               bbox     score  \\\n",
       "17        37  [1719.8165283203125, 1541.7166748046875, 1764....  0.526125   \n",
       "18        37  [1716.9451904296875, 1537.9757080078125, 1770....  0.065791   \n",
       "\n",
       "    category_id  \n",
       "17            0  \n",
       "18            1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_annotations_df[pred_annotations_df.image_id == 37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the categories\n",
    "categories = sorted(gt_annotations_df.category_id.unique())\n",
    "categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 110 Predicted: 163\n",
      "True positives: 86 False positives: 77\n",
      "Category: Crypto, Precision: 0.5276073619631901, Recall: 0.7818181818181819\n",
      "Actual: 59 Predicted: 82\n",
      "True positives: 50 False positives: 32\n",
      "Category: Giardia, Precision: 0.6097560975609756, Recall: 0.847457627118644\n"
     ]
    }
   ],
   "source": [
    "# Precision x Recall is obtained individually by each class\n",
    "# Loop through each class and calculate the precision and recall\n",
    "\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)\n",
    "\n",
    "for category in categories:\n",
    "    # get the ground truth annotations for the current class\n",
    "    gt_annotations_df_class = gt_annotations_df[\n",
    "        gt_annotations_df.category_id == category\n",
    "    ]\n",
    "    # get the predicted annotations for the current class\n",
    "    pred_annotations_df_class = pred_annotations_df[\n",
    "        pred_annotations_df.category_id == category\n",
    "    ]\n",
    "\n",
    "    # sort the predicted annotations by score\n",
    "    pred_annotations_df_class = pred_annotations_df_class.sort_values(\n",
    "        by=\"score\", ascending=False\n",
    "    )\n",
    "\n",
    "    # filter predictions with score > 0.3\n",
    "    pred_annotations_df_class = pred_annotations_df_class[\n",
    "        pred_annotations_df_class.score > 0.3\n",
    "    ]\n",
    "\n",
    "    true_positives_class = 0\n",
    "    false_positives_class = 0\n",
    "\n",
    "    # get image ids for the current class from both ground truth and predicted annotations\n",
    "    image_ids = pred_annotations_df_class[\"image_id\"].unique()\n",
    "    images_len = len(image_ids)\n",
    "\n",
    "    for image in image_ids:\n",
    "        # get the ground truth annotations for the current image\n",
    "        gt_annotations_df_image = gt_annotations_df_class[\n",
    "            gt_annotations_df_class.image_id == image\n",
    "        ]\n",
    "        # get the predicted annotations for the current image\n",
    "        pred_annotations_df_image = pred_annotations_df_class[\n",
    "            pred_annotations_df_class.image_id == image\n",
    "        ]\n",
    "\n",
    "        # get the ground truth bounding boxes\n",
    "        gt_bboxes = list(gt_annotations_df_image.bbox.values)\n",
    "        gt_bboxes = torch.tensor(gt_bboxes)\n",
    "\n",
    "        # get the predicted bounding boxes\n",
    "\n",
    "        # only take the predicted bounding boxes which have a score > 0.3\n",
    "        pred_bboxes = list(pred_annotations_df_image.bbox.values)\n",
    "        pred_bboxes = torch.tensor(pred_bboxes)\n",
    "\n",
    "\n",
    "        if len(gt_bboxes) == 0:\n",
    "            false_positives_class += len(pred_bboxes)\n",
    "            continue\n",
    "\n",
    "        # get the intersection over union for each predicted bounding box\n",
    "        ious = box_iou(gt_bboxes, pred_bboxes)\n",
    "\n",
    "        # get the maximum iou for each ground truth bounding box\n",
    "        max_ious, _ = torch.max(ious, dim=0)\n",
    "\n",
    "        # get the indices of the predicted bounding boxes with iou > 0.5\n",
    "        tp_indices = torch.where(max_ious >= 0.5)[0]\n",
    "        # print(ious)\n",
    "\n",
    "        # get the indices of the predicted bounding boxes with iou < 0.5\n",
    "        fp_indices = torch.where(max_ious < 0.5)[0]\n",
    "\n",
    "        # update the true positives and false positives\n",
    "        true_positives_class += len(tp_indices)\n",
    "        false_positives_class += len(fp_indices)\n",
    "\n",
    "    # print actual number of ground truth annotations and predicted annotations for the current class\n",
    "    print(\n",
    "        \"Actual:\",\n",
    "        gt_annotations_df_class.shape[0],\n",
    "        \"Predicted:\",\n",
    "        pred_annotations_df_class.shape[0],\n",
    "    )\n",
    "\n",
    "    # print true positives and false positives for the current class\n",
    "    print(\n",
    "        \"True positives:\",\n",
    "        true_positives_class,\n",
    "        \"False positives:\",\n",
    "        false_positives_class,\n",
    "    )\n",
    "    # calculate the precision and recall\n",
    "    precision = true_positives_class / (true_positives_class + false_positives_class)\n",
    "    recall = true_positives_class / gt_annotations_df_class.shape[0]\n",
    "\n",
    "    category_name = gt_annotations[\"categories\"][category][\"name\"]\n",
    "    print(f\"Category: {category_name}, Precision: {precision}, Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bbox for image_id=1\n",
    "gt_bbox_1 = gt_annotations_df[gt_annotations_df[\"image_id\"] == 259]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bbox_1 = pred_annotations_df[pred_annotations_df[\"image_id\"] == 259]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>259</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>[1091.0, 1389.0, 1177.0, 1497.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>9288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>259</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>[878.0, 2338.0, 944.0, 2414.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>5016.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id   id  category_id                              bbox segmentation  \\\n",
       "43       259  171            1  [1091.0, 1389.0, 1177.0, 1497.0]           []   \n",
       "44       259  172            0    [878.0, 2338.0, 944.0, 2414.0]           []   \n",
       "\n",
       "    iscrowd    area  \n",
       "43        0  9288.0  \n",
       "44        0  5016.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_bbox_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>score</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>259</td>\n",
       "      <td>[1105.5439453125, 1390.0980224609375, 1171.617...</td>\n",
       "      <td>0.998726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id                                               bbox     score  \\\n",
       "86       259  [1105.5439453125, 1390.0980224609375, 1171.617...  0.998726   \n",
       "\n",
       "    category_id  \n",
       "86            1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbox_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1677.4498, 1608.5356, 1737.7509, 1665.9437],\n",
       "        [1373.4507, 1647.2849, 1428.7148, 1704.8878],\n",
       "        [1364.7380, 1639.0117, 1435.4178, 1721.2365],\n",
       "        [1674.5179, 1607.7670, 1755.6367, 1674.7997]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbox_tensor = torch.tensor(pred_bbox_1[\"bbox\"].values.tolist())\n",
    "pred_bbox_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1367., 1633., 1453., 1709.],\n",
       "        [1643., 1611., 1741., 1687.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_bbox_tensor = torch.tensor(gt_bbox_1[\"bbox\"].values.tolist())\n",
    "gt_bbox_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_iou = box_iou(gt_bbox_tensor, pred_bbox_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.4871, 0.6335, 0.0000],\n",
       "        [0.4361, 0.0000, 0.0000, 0.4907]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in pairwise_iou.numpy():\n",
    "    print(i.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.48705268, 0.63346106, 0.        ],\n",
       "       [0.43613747, 0.        , 0.        , 0.49068674]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmdet.core.evaluation.bbox_overlaps import bbox_overlaps\n",
    "\n",
    "bbox_overlaps(gt_bbox_tensor.numpy(), pred_bbox_tensor.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
